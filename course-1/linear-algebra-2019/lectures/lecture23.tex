\section{Лекция 05.03.2020}

\begin{example}
    $\EE = \RR^n$ со стандартным скалярным произведением.

    Тогда, стандартный базис является ортонормированным.
    \begin{equation*}
        \begin{pmatrix} 1 \\ 0 \\ \dots \\ 0 \end{pmatrix},
        \begin{pmatrix} 0 \\ 1 \\ \dots \\ 0 \end{pmatrix},
        \dots,
        \begin{pmatrix} 0 \\ 0 \\ \dots \\ 1 \end{pmatrix}
    .\end{equation*}
\end{example}


\subsection{Теорема о существовании ортонормированного базиса}

\begin{theorem}
    Во всяком конечномерном евклидовом пространстве существует ортонормированный базис.
\end{theorem}

\begin{proof}
    Следует из теоремы о приведении квадратичной формы $(x, x)$ к нормальному виду (который будет $E$ в силу положительной определённости).
\end{proof}

\begin{corollary}
    Всякую ортогональную (ортонормированную) систему векторов можно дополнить до ортогонального (ортонормированного) базиса.
\end{corollary}

\begin{proof}
    Пусть $e_1, \dots, e_k$ --- данная система. 

    Пусть $e_{k + 1}, \dots, e_{n}$ --- это ортогональный (ортонормированный) базис в $\left< e_1, .., e_k \right>^{\perp}$.

    Тогда $e_1, \dots, e_n$ --- искомый базис.
\end{proof}


\subsection{Описание всех ортонормированных базисов в терминах одного ортонормированного базиса и матриц перехода}

Пусть $\E = (e_1, \dots, e_n)$ --- ортонормированный базис в $E$.

Пусть $\E' = (e'_1, \dots, e'_n)$ --- какой-то другой базис.

$(e'_1, \dots, e'_n) = (e_1, \dots, e_n) \cdot C$, $C \in M_n^{0}(\RR)$.

\begin{proposal}
    $\E'$ --- ортонормированный базис $\iff C^{T} \cdot C = E$.
\end{proposal}

\begin{proof}
    $G(e'_1, \dots, e'_n) = C^{T} \underbracket{G(e_1, \dots, e_n)}_E C = C^{T} C$.

    $\E'$ ортонормированный $\iff G(e'_1, \dots, e'_n) = E \iff C^{T} C = E$.
\end{proof}


\subsection{Ортогональные матрицы и их свойства}

\begin{definition}
    Матрица $C \in M_n(\RR)$ называется \textit{ортогональной} если $C^{T} C = E$.
\end{definition}

\begin{comment}
    $C^{T} C = E \iff C C^{T} = E \iff C^{-1} = C^{T}$.
\end{comment}

\begin{properties}~
    \begin{enumerate}
    \item $C^{T} C = E \implies $ система столбцов $C^{(1)}, \dots, C^{(n)}$ --- это ортонормированный базис в $\RR^n$,
    \item $C C^{T} = E \implies $ система строк $C_{(1)}, \dots, C_{(n)}$ --- это тоже ортонормированный базис в $\RR^n$,
    \end{enumerate}
    В частности, $|c_{ij}| \leq 1$.
    \begin{enumerate}[resume]
    \item $\det C = \pm 1$.
    \end{enumerate}
\end{properties}

\begin{example}
    $n = 2$.
    Ортогональный матрицы:
    \begin{equation}
        \begin{gathered}
            \begin{pmatrix} 
                \cos \phi & -\sin \phi \\
                \sin \phi & \cos \phi
            \end{pmatrix} \\
            \det = 1
        \end{gathered}
        \hspace{1cm}
        \begin{gathered}
            \begin{pmatrix} 
                \cos \phi & \sin \phi \\
                \sin \phi & -\cos \phi
            \end{pmatrix} \\
            \det = -1
        \end{gathered}
    .\end{equation}
\end{example}


\subsection{Координаты вектора в ортогональном (ортонормированном) базисе}

Пусть $\EE$ --- евклидово пространство, $(e_1, \dots, e_n)$ --- ортогональный базис.

$v \in \EE$.

\begin{proposal}
    $v = \dfrac{(v, e_1)}{(e_1, e_1)}e_1 + \dfrac{(v, e_2)}{(e_2, e_2)}e_2 + \dots + \dfrac{(v, e_n)}{(e_n, e_n)}e_n$.

    В частности, если $e_1, \dots, e_n$ ортонормирован, то $v = (v, e_1)e_1 + \dots + (v, e_n) e_n$.
\end{proposal}

\begin{proof}
    $v = \lambda_1 e_1 + \lambda_2 e_2 + \dots \lambda_n e_n$.

    $\forall i = 1, \dots, n \quad (v, e_i) = \lambda_1 (e_1, e_i) + \dots + \lambda_n (e_n, e_i)$.

    Так как базис ортогонален, то $(v, e_i) = \lambda_i (e_i, e_i) \implies \lambda_i = \dfrac{(v, e_i)}{(e_i, e_i)}$.
\end{proof}


\subsection{Формула для ортогональной проекции вектора на подпространство в терминах его ортогонального (ортонормированного) базиса}


Пусть $S \subseteq \EE$ --- подпространство.

$e_1, \dots, e_k$ --- ортогональный базис в $S$.

\begin{proposal}
    $\forall v \in \EE \quad \pr_S v = \sum_{i = 1}^{k} \dfrac{(v, e_i)}{(e_i, e_i)} e_i$.

    В частности, если $e_1, \dots, e_k$ ортонормирован, то $\pr_S v = \sum_{i = 1}^{k} (v, e_i) e_i$.
\end{proposal}

\begin{proof}
    Пусть $e_{k + 1}, \dots, e_n$ --- ортогональный базис в $S^{\perp}$. Тогда $e_1, \dots, e_n$ --- ортогональный базис в $\EE$.

    \begin{equation*}
        v = \underbrace{\sum_{i = 1}^{k} \dfrac{(v, e_i)}{(e_i, e_i)} e_i}_{\in S} + \underbrace{\sum_{i = k + 1}^{n} \dfrac{(v, e_i)}{(e_i, e_i)} e_i}_{\in S^{\perp}}
    .\end{equation*}

    Отсюда,
    \begin{equation*}
        \pr_S v = \sum_{i = 1}^{k} \dfrac{(v, e_i)}{(e_i, e_i)}
    .\qedhere\end{equation*}
\end{proof}


\subsection{Метод ортогонализации Грама–Шмидта}

Как построить ортогональный (ортонормированный) базис в $\EE$?

Если $f_1, \dots, f_n$ --- ортогональный базис, то $\left(\frac{f_1}{|f_1|}, \dots, \frac{f_n}{|f_n|}\right)$ --- ортонормированный базис.

Тогда, достаточно построить ортогональный базис.

Пусть $e_1, \dots, e_k$ --- линейно независимая система векторов.

$i$-й угловой минор в $G(e_1, \dots, e_k)$ --- это $\det G(e_1, \dots, e_k) > 0$.

\bigskip
Следовательно, применим метод Якоби:

$\exists!$ система векторов $f_1, \dots, f_k$, такая что 
\begin{align*}
&f_1 = e_1, \\
&f_2 \in e_2 + \left< e_1 \right>, \\
&f_3 \in e_3 + \left< e_1, e_2 \right>, \\
&\dots, \\
&f_k \in e_k + \left< e_1, \dots, e_{k - 1} \right>
\end{align*}


И выполнены следующие свойства $\forall i = 1, \dots, k$:

\begin{enumerate}[start=0,nosep]
\item $f_1, \dots, f_k$ ортогональны.
\item $\left< e_1, \dots, e_i \right> = \left< f_1, \dots, f_i \right>$.
\item $f_i = e_i - \sum_{j = 1}^{i - 1} \dfrac{(e_i, f_j)}{(f_j, f_j)} f_j$ \customlabel{lec23:star}{($\star$)}.
\item $\det G(e_1, \dots, e_i) = \det G(f_1, \dots, f_i)$ \customlabel{lec23:heart}{$(\heartsuit)$}.
\end{enumerate}

\bigskip
Построение базиса $f_1, \dots, f_k$ по формулам \ref{lec23:star} называется методом (процессом) ортогонализации Грамма-Шмидта.

\begin{comment}
    Свойство 2) говорит, что 
    \begin{equation*}
        f_i = e_i - \pr_{\left< f_1, \dots, f_{i - 1}\right>} e_i = \ort_{\left< f_1, \dots, f_{i - 1} \right>} e_i
    .\end{equation*}
\end{comment}


\subsection{Теорема Пифагора в евклидовом пространстве}

\begin{theorem}
    Пусть $x, y \in \EE$, $(x, y) = 0$. Тогда $|x + y|^2 = |x|^2 + |y|^2$.
\end{theorem}

\begin{proof}
    \begin{equation*}
        |x + y|^2 = (x + y, x + y) = \underbrace{(x, x)}_{|x|^2} + \underbrace{(x, y)}_{0} + \underbrace{(y, x)}_{0} + \underbrace{(y, y)}_{|y|^2} = |x|^2 + |y|^2
    .\qedhere\end{equation*}
\end{proof}


\subsection{Расстояние между векторами евклидова пространства}

\begin{definition}
    \textit{Расстояние} между векторами $x, y \in \EE$ --- это $\rho(x, y) = |x - y|$.
\end{definition}


\subsection{Неравенство треугольника}

\begin{proposal}
    $\forall a, b, c \in \EE \implies \rho(a, b) + \rho(b, c) \geq \rho(a, c)$.
\end{proposal}

\begin{proof}
    Пусть $x = a - b$, $y = b - c$. Тогда, $a - c = x + y$.
    Достаточно доказать, что $|x| + |y| \geq |x + y|$.

    \begin{equation*}
        |x + y|^2 = |x|^2 + \underbrace{2(x, y)}_{\leq |x||y|} + |y|^2 \leq |x|^2 + 2|x||y| + |y|^2 = (|x| + |y|)^2
    .\qedhere\end{equation*}
\end{proof}


\subsection{Расстояние между двумя подмножествами евклидова пространства}

Пусть $P, Q \subseteq \EE$ --- два подмножества.

\begin{definition}
    \textit{Расстояние} между $P$ и $Q$ --- это
    \begin{equation*}
        \rho(P, Q) := \inf_{x \in P, y \in Q} \rho(x, y)
    .\end{equation*}
\end{definition}


\subsection{Теорема о расстоянии от вектора до подпространства}

\begin{theorem}
    Пусть $x \in \EE$, $S \subseteq \EE$ --- подпространство. Тогда, $\rho(x, S) = \left|\ort_S x\right|$, причем $\pr_S x$ --- это ближайший к $x$ вектор из $S$.
\end{theorem}

\begin{proof}
    Положим $y = \pr_S x$, $z = \ort_S x$. Тогда, $x = y + z$.
    Для любого $y' \in S$, $y' \neq 0$ имеем
    \begin{equation*}
        \rho(x, y + y')^2 = |x - y - y'|^2 = |z - y'|^2 = |z|^2 + |y'|^2 > |z|^2 = |x - y|^2 = \rho(x, y)^2
    .\qedhere\end{equation*}
\end{proof}


\subsection{Псевдорешение несовместной системы линейных уравнений (метод наименьших квадратов)}

СЛУ $Ax = b$, $A \in \text{Mat}_{m \times n}(\RR)$, $x \in \RR^n$, $b \in \RR^m$.
\begin{equation*}
    x_0 \text{ --- решение системы} \iff Ax_0 = b \iff Ax_0 - b = 0 \iff |Ax_0 - b| = 0 \iff \rho(Ax_0, b) = 0
.\end{equation*}

Если СЛУ несовместна, то $x_0$ называется \textit{псевдорешением}, если $\rho(Ax_0, b)$ минимально.

\begin{equation*}
    \rho(Ax_0, b) = \min_{x \in R^n} \rho(Ax, b)
.\end{equation*}

$x_0$ --- решение задачи оптимизации $\rho(Ax, b) \xrightarrow[x \in \RR^n]{} \min$.
